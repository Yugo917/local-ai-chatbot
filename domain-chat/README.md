# ğŸ§  GenAI Corpus Suite â€“ Modular System for Managing and Leveraging Domain Corpora for AI

This repository provides a full-stack architecture to **structure**, **transform**, **vectorize**, **query**, and **customize** business data for use with language models (LLMs).

Built to be **modular**, **scalable**, and **maintainable**, the GenAI Corpus Suite is designed to address real-world business needs with a strong focus on **efficiency** and **relevance**.

### ğŸš€ Key Benefits

âœ… **Business-grade answers**: Responses are generated using **your domain-specific data** (FAQs, tickets, documents, visuals...) for maximum relevance and accuracy
ğŸ’° **Cost optimization**: Reduces the number of paid LLM API calls via intelligent caching and pre-prompt generation
âš¡ **Faster responses**: Minimizes latency with a smart vector search and reusable response memory
ğŸ§  **Smarter fine-tuning**: Adapts models using **parameter-efficient techniques** (LoRA, QLoRAâ€¦) to cut down training time and compute costs

Whether youâ€™re building a **chatbot**, **semantic search engine**, or an **AI assistant tailored to your business**, GenAI Corpus Suite helps you **scale with control, precision, and impact**.

---

## ğŸ—ï¸ Global Architecture â€“ A Complete Pipeline for Leveraging Domain AI

1. ğŸ“¥ Document ingestion and structuring: `CorpusApi`
2. ğŸ”„ Data conversion and vectorization: `DataToolApi`
3. ğŸ§ª Model customization: `LLMApi`
4. ğŸ’¬ Intelligent answering: `OptimizedAgent`

Each component can work **independently** or in **synergy** with the others.

![Archi](docs/archi/archi.png)

---

## âœ¨ Key Advantages

âœ… **Modular** and **extensible** architecture
â˜ï¸ Compatible with **local or cloud-based** LLMs
âš™ï¸ Resource optimization via **embeddings**, **caching**, and **lightweight fine-tuning**
ğŸ§© Designed for business use cases: **customer support**, **document retrieval**, **chat agents**...

---

## ğŸ¤– 1. `OptimizedAgent` â€“ Smart Agent with Memory and Context

Designed to respond to user queries quickly and accurately:

* ğŸ—ƒï¸ Searches in a **vector cache** (`CachedAgentResponse`) to reuse validated answers.
* ğŸ§  Generates **enriched pre-prompts** (`PrepromptEnhancer`) if no relevant answer is found.

ğŸ“ˆ The system dynamically adapts and **optimizes LLM calls**.

ğŸ“„ [See the detailed documentation](docs/archi/GEN_AI.md)

---

## ğŸ“š 2. `CorpusApi` â€“ Centralized Management of Business Corpus

This module organizes textual data in two layers:

* ğŸ“– **`BaseCorpus`**: generic linguistic resources (glossary, synonyms, paraphrases).
* ğŸ§© **`DomainCorpus`**: supports business documents (FAQs, tickets, visual or technical documents), chunking, enrichment, vectorization.
* ğŸ—‚ï¸ **Raw document storage**: allows for **replay**, **future regeneration**, and **direct link insertion** to sources in AI answers.

ğŸ“„ [See the detailed documentation](docs/archi/DATA.md)

---

## ğŸ§° 3. `DataToolApi` â€“ Data Transformation and Vectorization

This API orchestrates two essential modules:

* ğŸ”„ **`DataConverter`**: converts raw files (Markdown, Word, images, chats...) into usable **data chunks** or **FAQs**.
* ğŸ“ **`EmbeddingsCreator`**: generates **semantic vectors** enriched with metadata for each segment.

ğŸ” This pipeline prepares data for **intelligent indexing** or **conversational exploitation**.

ğŸ“„ [See the detailed documentation](docs/archi/TOOLS.md)

---

## ğŸ§ª 4. `LLMApi` â€“ Efficient Fine-Tuning of Language Models

This component allows a LLM to be tailored to a business use case with minimal resources:

* ğŸ§  **`PETFGenerator`**: generates configurations for lightweight fine-tuning (LoRA, QLoRA, AdaLoRA...).
* ğŸ› ï¸ **`FineTunedModelGenerator`**: applies these configurations to produce a **customized model**.

ğŸ’¡ Ideal for building **specialized models** without heavy computational loads.

ğŸ“„ [See the detailed documentation](docs/archi/LLM.md)

---
