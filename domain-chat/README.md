# ğŸ§  GenAI Corpus Suite â€“ SystÃ¨me modulaire de gestion et dâ€™exploitation de corpus mÃ©tier pour lâ€™IA

Ce dÃ©pÃ´t propose une architecture complÃ¨te pour **structurer**, **transformer**, **vectoriser**, **interroger** et **personnaliser** des donnÃ©es mÃ©tier en vue de les exploiter avec des modÃ¨les de langage (LLM).
Lâ€™ensemble est conÃ§u de faÃ§on **modulaire** pour faciliter la scalabilitÃ©, la maintenabilitÃ© et lâ€™adaptation Ã  diffÃ©rents cas dâ€™usage.

---

## ğŸ—ï¸ Architecture globale â€“ Un pipeline complet pour exploiter lâ€™IA mÃ©tier

1. ğŸ“¥ Ingestion et structuration des documents : `CorpusApi`
2. ğŸ”„ Conversion et vectorisation des donnÃ©es : `DataToolApi`
3. ğŸ§ª Personnalisation du modÃ¨le : `LLMApi`
4. ğŸ’¬ RÃ©ponse intelligente : `OptimizedAgent`

Chaque brique peut fonctionner **indÃ©pendamment** ou en **synergie** avec les autres.

![Archi](docs/archi/archi.png)

---

## âœ¨ Avantages clÃ©s

âœ… Architecture **modulaire** et **extensible**
â˜ï¸ Compatible avec des modÃ¨les LLM **locaux ou cloud**
âš™ï¸ Optimisation des ressources via **embeddings**, **cache** et **fine-tuning allÃ©gÃ©**
ğŸ§© ConÃ§u pour les cas dâ€™usage mÃ©tiers : **support client**, **recherche documentaire**, **agents conversationnels**â€¦

---

## ğŸ¤– 1. `OptimizedAgent` â€“ Agent intelligent avec mÃ©moire et contexte

ConÃ§u pour rÃ©pondre aux requÃªtes utilisateur de maniÃ¨re rapide et pertinente :

* ğŸ—ƒï¸ Recherche dans un **cache vectoriel** (`CachedAgentResponse`) pour rÃ©utiliser des rÃ©ponses validÃ©es.
* ğŸ§  GÃ©nÃ©ration de **prÃ©-prompts enrichis** (`PrepromptEnhancer`) si aucune rÃ©ponse pertinente nâ€™est trouvÃ©e.

ğŸ“ˆ Le systÃ¨me sâ€™adapte dynamiquement et **optimise les appels LLM**.

ğŸ“„ [Voir la documentation dÃ©taillÃ©e](docs/archi/GEN_AI.md)

---

## ğŸ“š 2. `CorpusApi` â€“ Gestion centralisÃ©e du corpus mÃ©tier

Ce module pilote lâ€™organisation des donnÃ©es textuelles en deux volets :

* ğŸ“– **`BaseCorpus`** : ressources linguistiques gÃ©nÃ©riques (glossaire, synonymes, paraphrases).
* ğŸ§© **`DomainCorpus`** : prise en charge des documents mÃ©tier (FAQ, tickets, documents visuels ou techniques), segmentation en chunks, enrichissement, vectorisation.
* ğŸ—‚ï¸ **Sauvegarde des documents bruts** : permet la **reprise**, la **rÃ©gÃ©nÃ©ration future**, et lâ€™**ajout de liens directs** vers les sources dans les rÃ©ponses IA.

ğŸ“„ [Voir la documentation dÃ©taillÃ©e](docs/archi/DATA.md)

---

## ğŸ§° 3. `DataToolApi` â€“ Transformation et vectorisation de donnÃ©es

Cette API orchestre deux modules essentiels :

* ğŸ”„ **`DataConverter`** : convertit des fichiers bruts (Markdown, Word, images, discussions...) en **datachunks** ou **FAQ** exploitables.
* ğŸ“ **`EmbeddingsCreator`** : gÃ©nÃ¨re des **vecteurs sÃ©mantiques** enrichis de mÃ©tadonnÃ©es pour chaque segment.

ğŸ” Ce pipeline prÃ©pare les donnÃ©es pour une **indexation intelligente** ou une **exploitation conversationnelle**.

ğŸ“„ [Voir la documentation dÃ©taillÃ©e](docs/archi/TOOLS.md)

---

## ğŸ§ª 4. `LLMApi` â€“ Fine-tuning efficace de modÃ¨les de langage

Ce composant permet dâ€™adapter un LLM Ã  un cas mÃ©tier donnÃ© avec un minimum de ressources :

* ğŸ§  **`PETFGenerator`** : gÃ©nÃ¨re des configurations de fine-tuning allÃ©gÃ© (LoRA, QLoRA, AdaLoRA...).
* ğŸ› ï¸ **`FineTunedModelGenerator`** : applique ces configurations pour produire un **modÃ¨le personnalisÃ©**.

ğŸ’¡ IdÃ©al pour crÃ©er des modÃ¨les **spÃ©cialisÃ©s**, sans lourde charge computationnelle.

ğŸ“„ [Voir la documentation dÃ©taillÃ©e](docs/archi/LLM.md)
